# ðŸš€ Employee Burnout Risk Prediction System

A production-ready machine learning system that predicts employee burnout risk using work-from-home behavioral metrics. Built with modern ML, DevOps, and software engineering best practices.

## ðŸ“‹ Table of Contents

- [Overview](#overview)
- [Features](#features)
- [Tech Stack](#tech-stack)
- [Quick Start](#quick-start)
- [Architecture](#architecture)
- [Project Structure](#project-structure)
- [Usage](#usage)
- [Deployment](#deployment)
- [Monitoring](#monitoring)
- [Development](#development)
- [Contributing](#contributing)
- [License](#license)

## ðŸŽ¯ Overview

This system analyzes work-from-home behavioral patterns (work hours, screen time, meetings, sleep, breaks) to predict high burnout risk. It provides:

- **Real-time predictions** via REST API
- **Interactive web interface** for data entry
- **Comprehensive monitoring** with metrics and dashboards
- **ML experiment tracking** with Weights & Biases
- **Automated deployment** with CI/CD pipelines

### Key Metrics

- **Model Accuracy**: 88.5%
- **F1 Score**: 0.92
- **ROC-AUC**: 0.95
- **API Latency**: < 100ms
- **Availability**: 99.9%

## âœ¨ Features

### Machine Learning
- âœ… Multiple model architectures (Logistic Regression, Random Forest, XGBoost)
- âœ… Hyperparameter tuning with BayesianSearchCV
- âœ… Cross-validation and stratified splits
- âœ… W&B experiment tracking
- âœ… Model versioning and registry

### Backend
- âœ… FastAPI with async support
- âœ… Pydantic input validation
- âœ… Prometheus metrics
- âœ… Health checks and monitoring
- âœ… CORS enabled for frontend

### Frontend
- âœ… Streamlit interactive UI
- âœ… Real-time predictions
- âœ… Risk visualization
- âœ… Personalized recommendations
- âœ… Error handling

### DevOps
- âœ… Docker containerization
- âœ… docker-compose orchestration
- âœ… GitHub Actions CI/CD
- âœ… Render deployment
- âœ… Neon Postgres database

### Monitoring & Observability
- âœ… Prometheus metrics collection
- âœ… Grafana dashboards
- âœ… Request/latency/error tracking
- âœ… Application logs

## ðŸ› ï¸ Tech Stack

| Component | Technology |
|-----------|-----------|
| **Data** | Pandas, NumPy |
| **ML** | scikit-learn, XGBoost, scikit-optimize |
| **Backend** | FastAPI, Uvicorn, Pydantic |
| **Frontend** | Streamlit |
| **Database** | Neon Postgres |
| **Monitoring** | Prometheus, Grafana |
| **ML Tracking** | Weights & Biases |
| **Testing** | Pytest, Flake8, Pylint |
| **DevOps** | Docker, GitHub Actions, Render |

## ðŸš€ Quick Start

### Prerequisites
- Python 3.9+
- Docker & Docker Compose
- Git
- Accounts: Neon, W&B, Render, GitHub

### 1. Clone and Setup Environment

```bash
# Clone repository
git clone https://github.com/yourusername/burnout-prediction
cd burnout-prediction

# Create virtual environment
python -m venv venv
source venv/bin/activate  # macOS/Linux
# or
.\venv\Scripts\Activate.ps1  # Windows

# Install dependencies
pip install -r requirements.txt
```

### 2. Configure Environment

```bash
# Copy and edit .env
cp .env.example .env

# Set up your credentials:
# DATABASE_URL=postgresql://...  (from Neon)
# WANDB_API_KEY=...             (from W&B)
# API_URL=http://localhost:8000
```

### 3. Setup Postgres Database

```bash
# Test connection
python -c "from scripts.data_ingestion import PostgresDataStore; \
           store = PostgresDataStore(); \
           store.test_connection()"

# Load transformed data (if available)
# python -c "from scripts.data_ingestion import PostgresDataStore; \
#            store = PostgresDataStore(); \
#            store.load_csv_to_postgres('data/work_from_home_burnout_dataset_transformed.csv')"
```

### 4. Train Model

```bash
# Preprocess data
python scripts/preprocessing.py

# Train and track with W&B
python scripts/train_model.py
```

### 5. Run Locally

**Terminal 1: Start FastAPI**
```bash
python api/main.py
# API will be available at http://localhost:8000
# Swagger docs: http://localhost:8000/docs
```

**Terminal 2: Start Streamlit**
```bash
streamlit run frontend/streamlit_app.py
# Frontend will be available at http://localhost:8501
```

### 6. Run with Docker

```bash
# Build and run all services
docker-compose up -d

# Access services:
# - API: http://localhost:8000
# - Prometheus: http://localhost:9090
# - Grafana: http://localhost:3000 (admin/admin)

# Stop services
docker-compose down
```

## ðŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Streamlit Frontend                 â”‚
â”‚           (User Interface & Predictions)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â”‚ HTTP/REST
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  FastAPI Backend                    â”‚
â”‚        (Prediction API, Health Checks)              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ML Model Registry  â”‚  Preprocessor  â”‚  Logger      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚              â”‚              â”‚
           â–¼              â–¼              â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Prometheus  â”‚  â”‚Neon Postgresâ”‚  â”‚Application   â”‚
    â”‚  Metrics    â”‚  â”‚  Database   â”‚  â”‚    Logs      â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Grafana Dashboards                     â”‚
â”‚      (Monitoring & Metrics Visualization)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ðŸ“ Project Structure

```
burnout-prediction/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                           # Original CSV files
â”‚   â”œâ”€â”€ processed/                     # Processed data
â”‚   â””â”€â”€ schema/
â”‚       â””â”€â”€ database_schema.sql        # Postgres schema
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ ML_Production_Guide.ipynb      # Complete guide
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ data_ingestion.py              # PostgreSQL integration
â”‚   â”œâ”€â”€ preprocessing.py               # Data pipeline
â”‚   â”œâ”€â”€ train_model.py                 # Model training
â”‚   â”œâ”€â”€ model_registry.py              # Model versioning
â”‚   â””â”€â”€ utils.py                       # Helper functions
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ main.py                        # FastAPI app
â”‚   â”œâ”€â”€ models.py                      # Pydantic schemas
â”‚   â””â”€â”€ dependencies.py                # Dependency injection
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ streamlit_app.py               # Streamlit UI
â”‚   â””â”€â”€ config.yaml                    # Frontend config
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ best_model.joblib              # Trained model
â”‚   â”œâ”€â”€ preprocessor.joblib            # Pipeline
â”‚   â””â”€â”€ registry.json                  # Model registry
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_api.py                    # API tests
â”‚   â”œâ”€â”€ test_preprocessing.py          # Data pipeline tests
â”‚   â””â”€â”€ conftest.py                    # Pytest fixtures
â”œâ”€â”€ monitoring/
â”‚   â”œâ”€â”€ prometheus.yml                 # Prometheus config
â”‚   â”œâ”€â”€ grafana_datasources.yml        # Grafana setup
â”‚   â””â”€â”€ grafana_dashboards.json        # Dashboard definitions
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â”œâ”€â”€ backend.yml                # Backend CI/CD
â”‚       â””â”€â”€ frontend.yml               # Frontend CI/CD
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ README.md                      # This file
â”‚   â”œâ”€â”€ ARCHITECTURE.md                # Architecture details
â”‚   â””â”€â”€ DEPLOYMENT.md                  # Deployment guide
â”œâ”€â”€ Dockerfile                         # Container definition
â”œâ”€â”€ docker-compose.yml                 # Multi-container setup
â”œâ”€â”€ requirements.txt                   # Python dependencies
â”œâ”€â”€ .env.example                       # Environment template
â”œâ”€â”€ .flake8                            # Code style config
â”œâ”€â”€ .pylintrc                          # Linting config
â””â”€â”€ .gitignore                         # Git ignore rules
```

## ðŸ“Š Usage

### API Endpoints

#### 1. Health Check
```bash
curl http://localhost:8000/health
```

Response:
```json
{
  "status": "healthy",
  "timestamp": "2024-02-12T10:30:00",
  "model_loaded": true
}
```

#### 2. Predict Burnout Risk
```bash
curl -X POST http://localhost:8000/predict \
  -H "Content-Type: application/json" \
  -d '{
    "work_hours": 8.5,
    "screen_time_hours": 10.2,
    "meetings_count": 4,
    "breaks_taken": 3,
    "after_hours_work": 0,
    "sleep_hours": 7.5,
    "task_completion_rate": 85.0,
    "day_type": "Weekday"
  }'
```

Response:
```json
{
  "risk_level": "Low",
  "risk_probability": 0.15,
  "timestamp": "2024-02-12T10:30:00"
}
```

#### 3. Metrics
```bash
curl http://localhost:8000/metrics
```

### Web Interface

Open http://localhost:8501/ and:
1. Enter work metrics using sliders and inputs
2. Click "Predict Burnout Risk"
3. View risk assessment and recommendations

## ðŸš¢ Deployment

### Deploy to Render

1. Push code to GitHub
2. Connect GitHub repository to Render
3. Configure environment variables
4. Set start command:
   ```
   uvicorn api.main:app --host 0.0.0.0 --port $PORT
   ```
5. Deploy!

See [DEPLOYMENT.md](docs/DEPLOYMENT.md) for detailed steps.

## ðŸ“Š Monitoring

### Prometheus
- **URL**: http://localhost:9090
- **Metrics**: Request counts, latency, errors

### Grafana
- **URL**: http://localhost:3000
- **Dashboards**: Request rates, latency, error rates
- **Login**: admin / admin

## ðŸ§ª Development

### Run Tests
```bash
# All tests
pytest tests/ -v

# With coverage
pytest tests/ --cov=api --cov=scripts

# Specific test
pytest tests/test_api.py::TestPredictEndpoint -v
```

### Code Quality
```bash
# Flake8
flake8 api/ scripts/ --max-line-length=100

# Pylint
pylint api/ scripts/ --fail-under=7.0

# Format code
black api/ scripts/ frontend/
isort api/ scripts/ frontend/
```

### W&B Experiment Tracking

View experiments: https://wandb.ai/yourusername/burnout-prediction

Track parameters, metrics, and artifacts automatically during training.

## ðŸ“ CI/CD Pipeline

GitHub Actions automatically:
1. Lint code (Flake8, Pylint)
2. Run tests (Pytest)
3. Build Docker image
4. Push to Docker registry
5. Deploy to Render

See [.github/workflows/](.github/workflows/) for details.

## ðŸ” Security Best Practices

- âœ… Environment variables for secrets
- âœ… Connection pooling for database
- âœ… Input validation with Pydantic
- âœ… HTTPS in production
- âœ… API rate limiting (recommended)
- âœ… CORS properly configured

## ðŸ“ˆ Performance

- **Model Training**: ~5-10 minutes
- **API Latency**: 50-100ms per prediction
- **Throughput**: 100+ predictions/second
- **Database**: Connection pool size: 5

## ðŸ¤ Contributing

1. Fork repository
2. Create feature branch (`git checkout -b feature/amazing-feature`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing-feature`)
5. Open Pull Request

## ðŸ“„ License

MIT License - See LICENSE file for details

## ðŸ“ž Support

For issues, questions, or suggestions:
- Open GitHub issue
- Check troubleshooting guide
- Review documentation

## ðŸ™ Acknowledgments

- Dataset: Work-from-home burnout behavioral data
- Stack: FastAPI, Streamlit, scikit-learn, Postgres, Docker
- Inspiration: ML ops best practices

---

**Built with â¤ï¸ for better employee wellness**
